{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "کتابدار برج بابِل</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    هدف این مسئله تشخیص برچسب‌های دسته‌بندی کتاب‌ها بر اساس خلاصه‌ی آن‌هاست. به این منظور، مجموعه‌ای از کتاب‌ها، خلاصه‌های آن‌ها و برچسب‌های آن‌ها در اختیار شما قرار گرفته است. هدف، ایجاد مدلی است که با دیدن یک خلاصه‌ی کتاب جدید حدس بزند که این کتاب شامل کدام برچسب‌ها می‌شود و کدام را شامل نمی‌شود.  </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "وارد کردن کتابخانه‌های مورد نیاز\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "\n",
    "<h2 align=\"right\" style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=\"rtl\" style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=\"3\">\n",
    "مجموعه‌ داده شامل اطلاعات مربوط به ۳۹۶۶ کتاب است که شامل داده‌های آموزشی و نمونه‌های آزمون می‌باشد. اطلاعات موجود برای هر کتاب شامل نام کتاب، خلاصه‌ی آن و برچسب‌های مربوطه است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\" style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=\"3\">\n",
    "داده‌های آموزشی در یک فایل با نام <code>train.csv</code> قرار دارد که شامل ۳۱۸۰ سطر می‌باشد. این فایل شامل ۹ دسته‌بندی است. قرار گرفتن در یک دسته‌بندی با عدد ۱ و عدم قرار گرفتن با عدد ۰ نشان داده می‌شود. توضیحات مربوط به ستون‌های مهم در این مسئله در جدول زیر آمده است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|title|عنوان کتاب یا مطلب|\n",
    "|description|توضیحات مربوط به کتاب|\n",
    "|Thriller|قرارگیری در دسته‌بندی تریلر|\n",
    "|Classics|قرارگیری در دسته‌بندی کلاسیک|\n",
    "|Romance|قرارگیری در دسته‌بندی عاشقانه|\n",
    "|Mystery|قرارگیری در دسته‌بندی معمایی|\n",
    "|Science|قرارگیری در دسته‌بندی علمی|\n",
    "|Literature|قرارگیری در دسته‌بندی ادبیات|\n",
    "|Fantasy|قرارگیری در دسته‌بندی فانتزی|\n",
    "|Historical|قرارگیری در دسته‌بندی تاریخی|\n",
    "|Fiction|قرارگیری در دسته‌بندی داستانی|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در ابتدا نیاز است فایل‌های مجموعه‌داده را بخوانید. نمونه‌های آموزشی در فایل <code>train.csv</code> و نمونه‌های آزمون که باید دسته‌بندی‌های آن‌ها را پیش‌بینی کنید در فایل <code>test.csv</code> ذخیره شده‌اند. اگر لازم دانستید می‌توانید به دلخواه خود بخشی از دادگان آموزشی را به عنوان دادگان اعتبارسنجی نیز جدا کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Classics</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Science</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Historical</th>\n",
       "      <th>Fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Not About the Bike: My Journey Back to Life</td>\n",
       "      <td>It is such an all-American story. A lanky kid ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trilogía Involuntaria #3The House of the Spirits</td>\n",
       "      <td>In one of the most important and beloved Latin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Girl Who Drank the Moon</td>\n",
       "      <td>Every year, the people of the Protectorate lea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Give Me Tomorrow: The Korean War's Greatest Un...</td>\n",
       "      <td>An epic story of valor and sacrifice by a lege...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The World of Winnie-the-Pooh</td>\n",
       "      <td>In 1926, \"Winnie-the-Pooh,\" a collection of st...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>Wisdom Revolution #2The Oldest Dance</td>\n",
       "      <td>As one of the war heroes searches the oldest l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>Mercy #3Beg For Mercy</td>\n",
       "      <td>The fight is on in this installment, Mercy is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>Halo #1Halo</td>\n",
       "      <td>An angel is sent to Earth on a mission.But fal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>Genius #1Evil Genius</td>\n",
       "      <td>Cadel Piggott has a genius IQ and a fascinatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>Warriors: Omen of the Stars #6The Last Hope</td>\n",
       "      <td>The end of the stars draws near. Three must be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2953 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0      It's Not About the Bike: My Journey Back to Life   \n",
       "1      Trilogía Involuntaria #3The House of the Spirits   \n",
       "2                           The Girl Who Drank the Moon   \n",
       "3     Give Me Tomorrow: The Korean War's Greatest Un...   \n",
       "4                          The World of Winnie-the-Pooh   \n",
       "...                                                 ...   \n",
       "2948               Wisdom Revolution #2The Oldest Dance   \n",
       "2949                              Mercy #3Beg For Mercy   \n",
       "2950                                        Halo #1Halo   \n",
       "2951                               Genius #1Evil Genius   \n",
       "2952        Warriors: Omen of the Stars #6The Last Hope   \n",
       "\n",
       "                                            description  Thriller  Classics  \\\n",
       "0     It is such an all-American story. A lanky kid ...         0         0   \n",
       "1     In one of the most important and beloved Latin...         0         0   \n",
       "2     Every year, the people of the Protectorate lea...         0         0   \n",
       "3     An epic story of valor and sacrifice by a lege...         0         0   \n",
       "4     In 1926, \"Winnie-the-Pooh,\" a collection of st...         0         1   \n",
       "...                                                 ...       ...       ...   \n",
       "2948  As one of the war heroes searches the oldest l...         0         0   \n",
       "2949  The fight is on in this installment, Mercy is ...         0         0   \n",
       "2950  An angel is sent to Earth on a mission.But fal...         0         0   \n",
       "2951  Cadel Piggott has a genius IQ and a fascinatio...         0         0   \n",
       "2952  The end of the stars draws near. Three must be...         0         0   \n",
       "\n",
       "      Romance  Mystery  Science  Literature  Fantasy  Historical  Fiction  \n",
       "0           0        0        0           0        0           0        0  \n",
       "1           0        0        0           1        1           1        1  \n",
       "2           0        0        0           0        0           0        1  \n",
       "3           0        0        0           0        0           0        1  \n",
       "4           0        0        0           0        1           0        1  \n",
       "...       ...      ...      ...         ...      ...         ...      ...  \n",
       "2948        0        0        1           0        1           0        1  \n",
       "2949        1        0        0           0        0           0        1  \n",
       "2950        1        0        0           0        1           0        0  \n",
       "2951        0        1        1           0        1           0        1  \n",
       "2952        0        0        0           0        1           0        1  \n",
       "\n",
       "[2953 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/train.csv') \n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb6ba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian Saga: Chronological Order #2Tai-Pan</td>\n",
       "      <td>Set in the turbulent days of the founding of H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prince of Pain #1Prince of Pain I</td>\n",
       "      <td>When Liam pays a madam for a specific fantasy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Practical Magic #1Practical Magic</td>\n",
       "      <td>Alternate cover for ISBN 9780425190371 (curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian Saga: Chronological Order #5Noble House</td>\n",
       "      <td>This is an alternate cover edition for ISBN13:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El Diablo #1El Diablo</td>\n",
       "      <td>FROM WALL STREET JOURNAL &amp; USA BESTSELLING AUT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Maybe #1.5Maybe Not</td>\n",
       "      <td>Colleen Hoover, the New York Times bestselling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>The Saga of Darren Shan #11Lord of the Shadows</td>\n",
       "      <td>Book 11 of The Saga Of Darren Shan. Darren's g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>The Highly Sensitive Person: How to Thrive Whe...</td>\n",
       "      <td>Do you have a keen imagination and vivid dream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Bad Girls Don't Die #3As Dead As It Gets</td>\n",
       "      <td>It's been three months since Alexis helplessly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>The Perfect Mother</td>\n",
       "      <td>An addictive psychological thriller about a gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0            Asian Saga: Chronological Order #2Tai-Pan   \n",
       "1                    Prince of Pain #1Prince of Pain I   \n",
       "2                    Practical Magic #1Practical Magic   \n",
       "3        Asian Saga: Chronological Order #5Noble House   \n",
       "4                                El Diablo #1El Diablo   \n",
       "..                                                 ...   \n",
       "734                                Maybe #1.5Maybe Not   \n",
       "735     The Saga of Darren Shan #11Lord of the Shadows   \n",
       "736  The Highly Sensitive Person: How to Thrive Whe...   \n",
       "737           Bad Girls Don't Die #3As Dead As It Gets   \n",
       "738                                 The Perfect Mother   \n",
       "\n",
       "                                           description  \n",
       "0    Set in the turbulent days of the founding of H...  \n",
       "1    When Liam pays a madam for a specific fantasy ...  \n",
       "2    Alternate cover for ISBN 9780425190371 (curren...  \n",
       "3    This is an alternate cover edition for ISBN13:...  \n",
       "4    FROM WALL STREET JOURNAL & USA BESTSELLING AUT...  \n",
       "..                                                 ...  \n",
       "734  Colleen Hoover, the New York Times bestselling...  \n",
       "735  Book 11 of The Saga Of Darren Shan. Darren's g...  \n",
       "736  Do you have a keen imagination and vivid dream...  \n",
       "737  It's been three months since Alexis helplessly...  \n",
       "738  An addictive psychological thriller about a gr...  \n",
       "\n",
       "[739 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec54",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پیش‌پردازش و مهندسی ویژگی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این سوال شما می‌توانید از هر تکنیک پیش‌پردازش/مهندسی ویژگی که در گذشته آموختید، استفاده کنید.\n",
    "    <br>\n",
    "    تکنیک‌هایی که استفاده می‌کنید به شکل مستقیم مورد ارزیابی توسط سامانه داوری قرار <b>نمی‌گیرند.</b> بلکه همه آن‌ها در دقت مدل شما تاثیر خواهند گذاشت؛ بنابراین هر چه پیش‌پردازش/مهندسی ویژگی بهتری انجام دهید تا دقت مدل بهبود پیدا کند، امتیاز بیشتری از این سوال کسب خواهید کرد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e457c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some preprocessing \n",
    "import re\n",
    "label_cols = [c for c in train_data.columns if c not in [\"title\", \"description\"]]\n",
    "train_data[\"description\"] = train_data[\"description\"].fillna(\"\")\n",
    "train_data[\"title\"] = train_data[\"title\"].fillna(train_data[\"description\"]).fillna(\"\")\n",
    "train_data[\"text_raw\"] = train_data[\"title\"].astype(str) + \" \" + train_data[\"description\"].astype(str)\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if pd.isna(s) else str(s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http[s]?://\\S+|www\\.\\S+\", \" \", s)       \n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)                       \n",
    "    s = s.replace(\"'\", \" \")\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)                    \n",
    "    s = re.sub(r\"\\b\\d+\\b\", \" \", s)                       \n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "train_data[\"text\"] = train_data[\"text_raw\"].apply(clean_text)\n",
    "train_data = train_data.drop_duplicates(subset=[\"text\"])\n",
    "train_data = train_data[train_data[\"text\"].str.len() > 0]\n",
    "if label_cols:\n",
    "    mask_any_label = train_data[label_cols].sum(axis=1) > 0\n",
    "    train_data = train_data[mask_any_label]\n",
    "train_data = train_data[[\"text\"] + label_cols].reset_index(drop=True)\n",
    "label_cols = [c for c in test_data.columns if c not in [\"title\", \"description\"]]\n",
    "test_data[\"description\"] = test_data[\"description\"].fillna(\"\")\n",
    "test_data[\"title\"] = test_data[\"title\"].fillna(test_data[\"description\"]).fillna(\"\")\n",
    "test_data[\"text_raw\"] = test_data[\"title\"].astype(str) + \" \" + test_data[\"description\"].astype(str)\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if pd.isna(s) else str(s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http[s]?://\\S+|www\\.\\S+\", \" \", s)       \n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)                       \n",
    "    s = s.replace(\"'\", \" \")\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)                   \n",
    "    s = re.sub(r\"\\b\\d+\\b\", \" \", s)                       \n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "test_data[\"text\"] = test_data[\"text_raw\"].apply(clean_text)\n",
    "test_data = test_data.drop_duplicates(subset=[\"text\"])\n",
    "test_data = test_data[test_data[\"text\"].str.len() > 0]\n",
    "if label_cols:\n",
    "    mask_any_label = test_data[label_cols].sum(axis=1) > 0\n",
    "    test_data = test_data[mask_any_label]\n",
    "if label_cols:\n",
    "    test_data = test_data[[\"text\"] + label_cols].reset_index(drop=True)\n",
    "else:\n",
    "    test_data = test_data[[\"text\"]].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2c94",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل‌سازی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال که داده را پاکسازی کرده و احتمالا ویژگی‌هایی را به آن افزوده یا از آن حذف کرده‌اید، وقت آن است که مدلی آموزش دهید که بتواند ستون‌های هدف این مسئله را پیش‌بینی کند.\n",
    "\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d20a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Predictions on Test Data ===\n",
      "   Thriller  Classics  Romance  Mystery  Science  Literature  Fantasy  \\\n",
      "0         0         0        0        0        0           0        0   \n",
      "1         0         0        1        0        0           0        1   \n",
      "2         0         0        1        0        0           0        1   \n",
      "3         0         0        0        0        0           0        0   \n",
      "4         0         0        1        0        0           0        1   \n",
      "\n",
      "   Historical  Fiction  \n",
      "0           0        1  \n",
      "1           0        1  \n",
      "2           0        1  \n",
      "3           0        1  \n",
      "4           0        1  \n"
     ]
    }
   ],
   "source": [
    "# modeling \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "X = train_data[\"text\"]\n",
    "y = train_data.drop(columns=[\"text\"])\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,  \n",
    "    ngram_range=(1, 2),  \n",
    "    stop_words=\"english\"\n",
    ")\n",
    "X_tr_tfidf = vectorizer.fit_transform(X_tr)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    ")\n",
    "clf.fit(X_tr_tfidf, y_tr)\n",
    "X_train_tfidf = vectorizer.fit_transform(X)\n",
    "clf.fit(X_train_tfidf, y)\n",
    "X_test = test_data[\"text\"]\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "predictions = pd.DataFrame(y_pred, columns=y.columns)\n",
    "print(\"\\n=== Sample Predictions on Test Data ===\")\n",
    "print(predictions.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da5d2a",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معیار ارزیابی\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    معیاری که برای ارزیابی عملکرد مدل انتخاب کرده‌ایم، <code>f1_score</code> نام دارد.\n",
    "    <br>\n",
    "    این معیار، سنجه ارزیابی کیفیت مدل شماست. به عبارت بهتر در سامانه داوری هم از همین معیار برای نمره‌دهی استفاده شده است.\n",
    "    <br>\n",
    "    این معیار برای هر مورد در ستون هدف به صورت جداگانه محاسبه شده و میانگین آن‌ها به عنوان امتیاز این مسئله در نظر گرفته می‌شود.\n",
    "    <br>\n",
    "    پیشنهاد می‌شود با توجه به این معیار، عملکرد مدل خود را بر روی مجموعه داده آموزش یا اعتبارسنجی ارزیابی کنید.\n",
    "    \n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee1b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Validation Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Thriller       0.00      0.00      0.00        73\n",
      "    Classics       0.00      0.00      0.00       128\n",
      "     Romance       0.00      0.00      0.00       192\n",
      "     Mystery       0.00      0.00      0.00        89\n",
      "     Science       0.00      0.00      0.00       105\n",
      "  Literature       0.00      0.00      0.00       101\n",
      "     Fantasy       0.56      0.02      0.04       237\n",
      "  Historical       0.00      0.00      0.00        92\n",
      "     Fiction       0.83      1.00      0.91       457\n",
      "\n",
      "   micro avg       0.83      0.31      0.45      1474\n",
      "   macro avg       0.15      0.11      0.11      1474\n",
      "weighted avg       0.35      0.31      0.29      1474\n",
      " samples avg       0.83      0.33      0.45      1474\n",
      "\n",
      "\n",
      "F1 micro: 0.4547244094488189\n",
      "F1 macro: 0.10546656825083825\n",
      "\n",
      "=== Confusion Matrices (per label) ===\n",
      "\n",
      "Label: Thriller\n",
      "[[476   0]\n",
      " [ 73   0]]\n",
      "\n",
      "Label: Classics\n",
      "[[421   0]\n",
      " [128   0]]\n",
      "\n",
      "Label: Romance\n",
      "[[357   0]\n",
      " [192   0]]\n",
      "\n",
      "Label: Mystery\n",
      "[[460   0]\n",
      " [ 89   0]]\n",
      "\n",
      "Label: Science\n",
      "[[444   0]\n",
      " [105   0]]\n",
      "\n",
      "Label: Literature\n",
      "[[448   0]\n",
      " [101   0]]\n",
      "\n",
      "Label: Fantasy\n",
      "[[308   4]\n",
      " [232   5]]\n",
      "\n",
      "Label: Historical\n",
      "[[457   0]\n",
      " [ 92   0]]\n",
      "\n",
      "Label: Fiction\n",
      "[[  0  92]\n",
      " [  0 457]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahdie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "from sklearn.metrics import  f1_score, classification_report, confusion_matrix\n",
    "y_val_pred = clf.predict(X_val_tfidf)\n",
    "print(\"=== Validation Classification Report ===\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=y.columns))\n",
    "\n",
    "print(\"\\nF1 micro:\", f1_score(y_val, y_val_pred, average=\"micro\"))\n",
    "print(\"F1 macro:\", f1_score(y_val, y_val_pred, average=\"macro\"))\n",
    "\n",
    "print(\"\\n=== Confusion Matrices (per label) ===\")\n",
    "for i, col in enumerate(y.columns):\n",
    "    cm = confusion_matrix(y_val.iloc[:, i], y_val_pred[:, i])\n",
    "    print(f\"\\nLabel: {col}\")\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e9984de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " پیش‌بینی بر اساس داده‌های ورودی و خروجی مورد انتظار\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پس از انجام فرآیند مهندسی ویژگی و مدل‌سازی، اکنون الگوریتمی در اختیار دارید که قادر است از داده‌های مستقل به نتایج مورد نظر دست یابد.\n",
    "    <br>\n",
    "    لطفاً از مدل خود برای پیش‌بینی برچسب دسته‌بندی کتاب‌های موجود در داده تست استفاده کنید و خروجی‌ها را در قالب یک جدول (<code>dataframe</code>) آماده کنید. داده‌های تست به صورت زیر خواهند بود:\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|Title|عنوان کتاب|\n",
    "|Description|توضیحات مرتبط با کتاب|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6d82d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اسم دیتافریم باید <i>submission</i> باشد؛ در غیر این صورت، سامانه داوری نمی‌تواند تلاش شما را ارزیابی کند.\n",
    "    <br>این دیتافریم باید شامل ۹ ستون باشد که هر کدام نمایانگر برچسب دسته‌بندی کتاب است و ۷۳۹ سطر دارد.\n",
    "    <br>\n",
    "    به ازای هر سطر موجود در دیتافریم <i>test</i> شما باید مقدار پیشبینی شده برای هر برچسب‌ داشته باشید.\n",
    "    <br>\n",
    "    جدول زیر، ۵ سطر ابتدایی دیتافریم <code>submission</code> را نشان می‌دهد. البته در جواب شما، مقادیر ممکن است متفاوت باشد.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "| Thriller | Classics | Romance | Mystery | Science | Literature | Fantasy | Historical | Fiction |\n",
    "|:--------:|:--------:|:-------:|:-------:|:-------:|:----------:|:-------:|:----------:|:-------:|\n",
    "|    0     |     1    |    0    |    0    |    0    |      0     |    0    |      1     |    1    |\n",
    "|    0     |     0    |    1    |    0    |    0    |      0     |    1    |      0     |    0    |\n",
    "|    0     |     0    |    1    |    0    |    0    |      0     |    1    |      0     |    1    |\n",
    "|    1     |     0    |    0    |    0    |    0    |      0     |    0    |      1     |    1    |\n",
    "|    0     |     0    |    1    |    0    |    0    |      0     |    0    |      0     |    0    |\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4a0844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Classics</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Science</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Historical</th>\n",
       "      <th>Fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian saga chronological order 2tai pan set in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prince of pain 1prince of pain i when liam pay...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>practical magic 1practical magic alternate cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian saga chronological order 5noble house th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el diablo 1el diablo from wall street journal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>maybe 5maybe not colleen hoover the new york t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>the saga of darren shan 11lord of the shadows ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>the highly sensitive person how to thrive when...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>bad girls don t die 3as dead as it gets it s b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>the perfect mother an addictive psychological ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  Thriller  Classics  \\\n",
       "0    asian saga chronological order 2tai pan set in...         0         0   \n",
       "1    prince of pain 1prince of pain i when liam pay...         0         0   \n",
       "2    practical magic 1practical magic alternate cov...         0         0   \n",
       "3    asian saga chronological order 5noble house th...         0         0   \n",
       "4    el diablo 1el diablo from wall street journal ...         0         0   \n",
       "..                                                 ...       ...       ...   \n",
       "729  maybe 5maybe not colleen hoover the new york t...         0         0   \n",
       "730  the saga of darren shan 11lord of the shadows ...         0         0   \n",
       "731  the highly sensitive person how to thrive when...         0         0   \n",
       "732  bad girls don t die 3as dead as it gets it s b...         0         0   \n",
       "733  the perfect mother an addictive psychological ...         0         0   \n",
       "\n",
       "     Romance  Mystery  Science  Literature  Fantasy  Historical  Fiction  \n",
       "0          0        0        0           0        0           0        1  \n",
       "1          1        0        0           0        1           0        1  \n",
       "2          1        0        0           0        1           0        1  \n",
       "3          0        0        0           0        0           0        1  \n",
       "4          1        0        0           0        1           0        1  \n",
       "..       ...      ...      ...         ...      ...         ...      ...  \n",
       "729        1        0        0           0        0           0        1  \n",
       "730        0        0        0           0        1           0        1  \n",
       "731        0        0        0           0        0           0        1  \n",
       "732        0        0        0           0        1           0        1  \n",
       "733        0        0        0           0        0           0        1  \n",
       "\n",
       "[734 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test samples\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "submission = pd.DataFrame(y_pred, columns=y_train.columns)\n",
    "submission = pd.concat([test_data[[\"text\"]].reset_index(drop=True), submission], axis=1)\n",
    "submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['Babel.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "            \n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['Babel.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625fa62-8aaa-459a-b550-b183fc366d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
